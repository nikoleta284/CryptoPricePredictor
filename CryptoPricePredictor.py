import requests
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from datetime import timedelta
import time
import os

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
SEQ_LENGTH = 30      # –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –º–æ–¥–µ–ª—å
PREDICT_STEPS = 20   # –ù–∞ —Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
EPOCHS = 100         # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
BATCH_SIZE = 16      # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

CRYPTOCURRENCIES = {
    '1': ('BTC', 'XXBTZUSD'),
    '2': ('ETH', 'XETHZUSD'),
    '3': ('XRP', 'XXRPZUSD'),
    '4': ('LTC', 'XLTCZUSD'),
}

INTERVALS = {
    '1': (15, '15 –º–∏–Ω—É—Ç'),
    '2': (60, '1 —á–∞—Å'),
    '3': (1440, '1 –¥–µ–Ω—å')
}

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def select_option(options, prompt, default_key):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."""
    print(prompt)
    for key, value in options.items():
        display_name = value[0] if isinstance(value, tuple) else value[1]
        print(f"{key}. {display_name}")
    choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä: ")
    return options.get(choice, options[default_key])

def get_historical_data(symbol, interval):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å API Kraken."""
    try:
        url = f'https://api.kraken.com/0/public/OHLC?pair={symbol}&interval={interval}'
        response = requests.get(url, timeout=10).json()
        if 'error' in response and response['error']:
            raise ValueError(f"–û—à–∏–±–∫–∞ API: {response['error']}")
        
        data_key = next(iter(response['result']))
        data = response['result'].get(data_key, [])
        
        if not data:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞—Ä—ã.")
            
        timestamps = [int(candle[0]) for candle in data]
        prices = [float(candle[4]) for candle in data]  # –¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è
        df = pd.DataFrame({'Price': prices}, index=pd.to_datetime(timestamps, unit='s'))
        return df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

# --- –ú–æ–¥–µ–ª–∏ ---

class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=2, dropout=0.2):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

class TransformerModel(nn.Module):
    def __init__(self, input_size=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):
        super(TransformerModel, self).__init__()
        self.embedding = nn.Linear(input_size, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc = nn.Linear(d_model, 1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.fc(x[:, -1, :])

# --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ ---

def create_sequences(data, seq_length):
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (X) –∏ —Ü–µ–ª–∏ (y) –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞."""
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[i - seq_length:i])
        y.append(data[i])
    return np.array(X), np.array(y)

def train_model(model, train_loader, val_loader, epochs=EPOCHS, patience=10):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ —Ä–∞–Ω–Ω–∏–º –æ—Å—Ç–∞–Ω–æ–≤–æ–º."""
    model.to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    best_loss = float('inf')
    patience_counter = 0
    model_save_path = 'best_model.pth'
    
    print(f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {type(model).__name__} –Ω–∞ {DEVICE}...")
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)
                outputs = model(inputs)
                val_loss += criterion(outputs, targets).item()

        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        
        print(f"–≠–ø–æ—Ö–∞ {epoch+1}/{epochs}, –ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {train_loss:.6f}, –ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {val_loss:.6f}")

        if val_loss < best_loss:
            best_loss = val_loss
            torch.save(model.state_dict(), model_save_path)
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"‚åõ –†–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}. –õ—É—á—à–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –ø–æ—Ç–µ—Ä—è: {best_loss:.6f}")
                break
    
    model.load_state_dict(torch.load(model_save_path))
    if os.path.exists(model_save_path):
        os.remove(model_save_path) 
    return model

def predict_future(model, scaler, last_sequence, predict_steps):
    """–ê–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ N —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥."""
    model.eval()
    
    last_sequence_tensor = torch.tensor(last_sequence.reshape(1, -1, 1), dtype=torch.float32).to(DEVICE)
    
    predictions_scaled = []
    with torch.no_grad():
        for _ in range(predict_steps):
            pred = model(last_sequence_tensor)
            predictions_scaled.append(pred.item())
            
            new_pred_tensor = pred.reshape(1, 1, 1)
            last_sequence_tensor = torch.cat([last_sequence_tensor[:, 1:, :], new_pred_tensor], dim=1)
            
    return scaler.inverse_transform(np.array(predictions_scaled).reshape(-1, 1)).flatten()

# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ---

def plot_interactive(df, val_df, predictions, interval_name, crypto_name):
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å –ø–æ–º–æ—â—å—é Plotly –∏ –≤–∫–ª—é—á–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∏—Å–æ–≤–∞–Ω–∏—è."""
    import plotly.graph_objects as go
    
    fig = go.Figure()

    fig.add_trace(go.Scatter(x=df.index, y=df['Price'], mode='lines', name='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–∞', line=dict(color='royalblue')))
    
    fig.add_vline(x=val_df.index[0], line=dict(color='gray', dash='dash'))

    colors = {'LSTM': 'red', 'Transformer': 'green'}
    for name, preds in predictions.items():
        fig.add_trace(go.Scatter(x=preds['index'], y=preds['values'], mode='lines', name=f'–ü—Ä–æ–≥–Ω–æ–∑ {name}', line=dict(color=colors[name], dash='dash')))

    fig.update_layout(
        title=f'–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã {crypto_name} (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {interval_name})',
        xaxis_title='–í—Ä–µ–º—è',
        yaxis_title='–¶–µ–Ω–∞ (USD)',
        template='plotly_white',
        hovermode='x unified',
        legend_title_text='–õ–µ–≥–µ–Ω–¥–∞'
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –¥–ª—è –Ω–∞—á–∞–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    fig.add_annotation(
        x=val_df.index[0],
        y=0.5,
        text='–ù–∞—á–∞–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏',
        showarrow=False,
        yref='paper'
    )

    # –í–∫–ª—é—á–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    config = {
        'modeBarButtonsToAdd': [
            'drawline',        # –†–∏—Å–æ–≤–∞–Ω–∏–µ –ª–∏–Ω–∏–π
            'drawopenpath',    # –†–∏—Å–æ–≤–∞–Ω–∏–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤
            'drawclosedpath',  # –†–∏—Å–æ–≤–∞–Ω–∏–µ –∑–∞–º–∫–Ω—É—Ç—ã—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤
            'drawcircle',      # –†–∏—Å–æ–≤–∞–Ω–∏–µ –∫—Ä—É–≥–æ–≤
            'drawrect',        # –†–∏—Å–æ–≤–∞–Ω–∏–µ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
            'eraseshape'       # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏–≥—É—Ä
        ]
    }

    fig.show(config=config)
# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---

def main():
    crypto_name, crypto_symbol = select_option(CRYPTOCURRENCIES, "–í—ã–±–µ—Ä–∏—Ç–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—É:", '1')
    interval_minutes, interval_name = select_option(INTERVALS, f"–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è {crypto_name}:", '2')

    df = get_historical_data(crypto_symbol, interval_minutes)
    if df is None or len(df) < SEQ_LENGTH * 2:
        print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª—å—à–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–ª–∏ –¥—Ä—É–≥—É—é –≤–∞–ª—é—Ç—É.")
        return

    train_size = int(len(df) * 0.8)
    train_df, val_df = df.iloc[:train_size], df.iloc[train_size:]

    
    scaler = MinMaxScaler()
    scaled_train_data = scaler.fit_transform(train_df)
    scaled_val_data = scaler.transform(val_df)
    
    X_train, y_train = create_sequences(scaled_train_data, SEQ_LENGTH)
    X_val, y_val = create_sequences(scaled_val_data, SEQ_LENGTH)

    if len(X_val) == 0:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª—å—à–∏–π –ø–µ—Ä–∏–æ–¥.")
        return

    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))
    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    models_to_train = {'LSTM': LSTMModel(), 'Transformer': TransformerModel()}
    all_predictions = {}

   
    for name, model_instance in models_to_train.items():
        trained_model = train_model(model_instance, train_loader, val_loader)
        
        last_sequence_scaled = scaler.transform(df.iloc[-SEQ_LENGTH:])
        future_preds = predict_future(trained_model, scaler, last_sequence_scaled, PREDICT_STEPS)
        
        last_time = df.index[-1]
        freq_str = f"{interval_minutes}min"
        future_index = pd.date_range(start=last_time, periods=PREDICT_STEPS + 1, freq=freq_str)[1:]
        
        all_predictions[name] = {'values': future_preds, 'index': future_index}

  
    plot_interactive(df, val_df, all_predictions, interval_name, crypto_name)

if __name__ == "__main__":
    main()
